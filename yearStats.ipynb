{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a5f5317",
   "metadata": {},
   "source": [
    "### Notes\n",
    "I would normally use a configuration file, environment variables, or command-line arguments for the variables in the \"Credentials\" cell. However, given the format of the exercise, I feel just having the variables integrated in the notebook in their own cell is the simplest for everyone involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67980fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, re\n",
    "import numpy\n",
    "import pandas\n",
    "import boto3\n",
    "from enum import Enum\n",
    "from botocore.exceptions import ClientError, ReadTimeoutError, ConnectTimeoutError\n",
    "import sqlalchemy\n",
    "from sqlalchemy.sql import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06347b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "aws_access_key=\"\"\n",
    "aws_secret_key=\"\"\n",
    "aws_s3_bucket=\"\"\n",
    "postgres_host=\"\"\n",
    "postgres_port=5432\n",
    "postgres_user=\"\"\n",
    "postgres_password=\"\"\n",
    "postgres_database=\"postgres\"\n",
    "postgres_table=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIND_S3:\n",
    "    \"\"\"Holds AWS S3 credentials and session as well as performs actions against S3.\"\"\"\n",
    "    aws_access_key = None\n",
    "    aws_secret_key = None\n",
    "    s3_client = None\n",
    "\n",
    "    # Defaults\n",
    "    max_keys = 1000\n",
    "\n",
    "\n",
    "    def __init__(self,access_key: str,secret_key: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the S3 client.\n",
    "\n",
    "        access_key: Your AWS Access Key ID\n",
    "\n",
    "        secret_key: Your cooresponding AWS Secret Key\n",
    "        \"\"\"\n",
    "        self.aws_access_key = access_key\n",
    "        self.aws_secret_key = secret_key\n",
    "        self.__login()\n",
    "\n",
    "    def __login(self,retries=0):\n",
    "        \"\"\"Attempt to login to AWS S3 using the saved credentials.\"\"\"\n",
    "        try:\n",
    "            self.s3_client = boto3.client(\n",
    "                \"s3\",\n",
    "                aws_access_key_id = self.aws_access_key,\n",
    "                aws_secret_access_key = self.aws_secret_key\n",
    "            )\n",
    "        except TimeoutError or ReadTimeoutError or ConnectTimeoutError as e:\n",
    "            if(retries > 2):\n",
    "                raise e\n",
    "            else:\n",
    "                self.__login(retries+1)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def list_all_objects(self,bucket: str,prefix=\"\") -> list:\n",
    "        \"\"\"\n",
    "        Paginate through all of the objects in a given bucket which contain a given prefix.\n",
    "\n",
    "        Warning: This can become an expensive process on large buckets.\n",
    "\n",
    "        Returns: list(object) -- Objects in format specified by boto3 list_objects_v2()\n",
    "\n",
    "        Args:\n",
    "\n",
    "        bucket -- The S3 bucket to perform the list on.\n",
    "\n",
    "        prefix -- The prefix to use when filtering results.\n",
    "        \"\"\"\n",
    "        objects = []\n",
    "        response = self.s3_client.list_objects_v2(\n",
    "            Bucket=bucket,\n",
    "            MaxKeys=self.max_keys,\n",
    "            Prefix=prefix\n",
    "        )\n",
    "\n",
    "        if(\"Contents\" in response):\n",
    "            objects.extend(response[\"Contents\"])\n",
    "        \n",
    "        while (\"NextContinuationToken\" in response):\n",
    "            response = self.s3_client.list_objects_v2(\n",
    "                Bucket=bucket,\n",
    "                MaxKeys=self.max_keys,\n",
    "                Prefix=prefix,\n",
    "                ContinuationToken=response[\"NextContinuationToken\"]\n",
    "            )\n",
    "            objects.extend(response[\"Contents\"])\n",
    "\n",
    "        return objects\n",
    "    \n",
    "    def pull_objects(self,bucket: str, destination: str, objects: list) -> list:\n",
    "        \"\"\"\n",
    "        Attempts to download the given list of objects from the given bucket and place then in a directory on\n",
    "        the local filesystem.\n",
    "\n",
    "        Returns: list(str) -- The the paths to each of the retrieved files.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        bucket -- The S3 bucket to pull from.\n",
    "\n",
    "        destination -- The target directory to store the retrieved objects. (Will be created if it doesn't already exist.)\n",
    "\n",
    "        objects -- A list of objects to pull. Must be in format [{\"Key\":\"object_key\"}]. MIND_S3.list_all_objects() returns this format.\n",
    "        \"\"\"\n",
    "        files = []\n",
    "        os.makedirs(destination,exist_ok=True)\n",
    "        for item in objects:\n",
    "            try:\n",
    "                obj = self.s3_client.get_object(\n",
    "                    Bucket=bucket,\n",
    "                    Key=item[\"Key\"]\n",
    "                )\n",
    "                if(\"Body\" in obj):\n",
    "                    file_path = \"%s/%s\"%(destination,item[\"Key\"])\n",
    "                    object_directory = os.path.dirname(file_path)\n",
    "                    os.makedirs(object_directory,exist_ok=True)\n",
    "\n",
    "                    with open(file_path,'wb') as file:\n",
    "                        file.write(obj[\"Body\"].read())\n",
    "\n",
    "                    files.append(file_path)\n",
    "            except ClientError as e:\n",
    "                if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "                    print(\"Object %s not found.\"%(item[\"Key\"]))\n",
    "\n",
    "        return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e05d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIND_Postgres:\n",
    "    \"\"\"Connects to a Postgres database and maintains the connection for future executions.\"\"\"\n",
    "    pg_host = None\n",
    "    pg_port = None\n",
    "    pg_username = None\n",
    "    pg_password = None\n",
    "    pg_database = None\n",
    "\n",
    "    pgsql = None\n",
    "\n",
    "    column_character_filter = re.compile(\"[^a-zA-Z0-9]\")\n",
    "\n",
    "\n",
    "    def __init__(self,host:str,port:int,username:str,password:str,database:str) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        host -- Postgres DB host\n",
    "\n",
    "        port -- Postgres DB conenction port\n",
    "\n",
    "        username -- Postgres DB Username\n",
    "\n",
    "        password -- Password for the Postgres DB Username\n",
    "\n",
    "        database -- Which database to connect to on the Postgres host.\n",
    "        \"\"\"\n",
    "        self.pg_host = host\n",
    "        self.pg_port = port\n",
    "        self.pg_username = username\n",
    "        self.pg_password = password\n",
    "        self.pg_database = database\n",
    "        self.__connect()\n",
    "\n",
    "    \n",
    "\n",
    "    def __connect(self):\n",
    "        self.pgsql = sqlalchemy.create_engine(\"postgresql://%s:%s/%s?password=%s&user=%s\"%(\n",
    "            self.pg_host,\n",
    "            self.pg_port,\n",
    "            self.pg_database,\n",
    "            self.pg_password,\n",
    "            self.pg_username\n",
    "        ))\n",
    "\n",
    "\n",
    "    def list_columns(self,table_name:str) -> list:\n",
    "        \"\"\"\n",
    "        Lists the columns and their data types from the desired table.\n",
    "\n",
    "        Returns -- List of tuples in format [('column_name', 'data_type')]\n",
    "\n",
    "        Args:\n",
    "\n",
    "        table_name -- The name of the table which to list columns for.\n",
    "        \"\"\"\n",
    "        with self.pgsql.connect() as con:\n",
    "            smt = text(\"select column_name, data_type from INFORMATION_SCHEMA.COLUMNS where table_name = '%s'\"%(table_name))\n",
    "            resp = con.execute(smt)\n",
    "        return list(resp)\n",
    "    \n",
    "    def clear_table(self,table_name:str) -> int:\n",
    "        \"\"\"\n",
    "        Clear the table of all rows.\n",
    "\n",
    "        Returns -- Number of rows deleted.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        table_name -- The name of the table which to clear.\n",
    "        \"\"\"\n",
    "        with self.pgsql.connect() as con:\n",
    "            smt = text(\"WITH deleted AS (DELETE FROM %s RETURNING *) SELECT count(*) FROM deleted;\"%(table_name))\n",
    "            resp = con.execute(smt)\n",
    "            con.commit()\n",
    "        return list(resp)\n",
    "    \n",
    "    def sanitize_column_name(self,column_name:str) -> str:\n",
    "        \"\"\"\n",
    "        Removes erroneous or otherwise ill-advised characters from a column name.\n",
    "\n",
    "        returns -- Column name, sanitized for use with SQL type databases.\n",
    "\n",
    "        Args:\n",
    "        \n",
    "        column_name -- Original name of the column\n",
    "        \"\"\"\n",
    "        new_name = list(re.sub(self.column_character_filter,\"|\",column_name))\n",
    "        first_character = True\n",
    "        for i in range(0,len(new_name)):\n",
    "            if(first_character == True and new_name[i] != \"|\"):\n",
    "                new_name[i] = new_name[i].lower()\n",
    "                first_character = False\n",
    "                continue\n",
    "            if(new_name[i] != \"|\" and new_name[i-1] == \"|\"):\n",
    "                new_name[i] = new_name[i].upper()\n",
    "\n",
    "        return \"\".join(new_name).replace(\"|\",\"\")\n",
    "        \n",
    "    \n",
    "    def add_column(self,table_name:str,column_name:str,data_type:str,constraint=\"\"):\n",
    "        \"\"\"\n",
    "        Adds a column of the specified data type to a given table.\n",
    "\n",
    "        Args:\n",
    "        \n",
    "        table_name -- Name of the table which to add the column\n",
    "\n",
    "        column_name -- The name of the column to add.\n",
    "\n",
    "        data_type -- The Postgres data type which the column stores.\n",
    "\n",
    "        constraint -- Optional addition of a constraint, such as \"NOT NULL\" or \"PRIMARY KEY\"\n",
    "        \"\"\"\n",
    "        with self.pgsql.connect() as con:\n",
    "            smt = text(\"ALTER TABLE %s ADD COLUMN \\\"%s\\\" %s %s\"%(table_name,column_name,data_type,constraint))\n",
    "            resp = con.execute(smt)\n",
    "            con.commit()\n",
    "\n",
    "\n",
    "\n",
    "    def push_data_frame(self,frame:pandas.DataFrame,table_name:str):\n",
    "        \"\"\"\n",
    "        Inserts a pandas DataFrame into a table.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        frame -- Pandas DataFrame to push\n",
    "\n",
    "        table_name -- Name of table to push DataFrame to.\n",
    "        \"\"\"\n",
    "        sanitized_columns = {}\n",
    "        for column in frame.columns:\n",
    "            sanitized_columns[column] = self.sanitize_column_name(column)\n",
    "        frame = frame.rename(columns=sanitized_columns)\n",
    "        frame.to_sql(table_name,self.pgsql,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result(Enum):\n",
    "    \"\"\"The possible results of a game.\"\"\"\n",
    "    WIN=1.0\n",
    "    LOSS=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_CSV_file(file_name: str) -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads in a CSV file and creates a pandas DataFrame from its contents.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    file_name -- path to the CSV file which should be parsed.\n",
    "    \"\"\"\n",
    "    frame = pandas.read_csv(file_name)\n",
    "    if(\"Yards\" in frame):\n",
    "        file_base_name = os.path.basename(file_name)\n",
    "        player_name = file_base_name.split(\"_\")[0].capitalize()\n",
    "        frame = frame.rename(columns={\n",
    "            \"Yards\":\"%s Yards\"%(player_name),\n",
    "            \"TD\":\"%s TD\"%(player_name),\n",
    "        })\n",
    "        return frame\n",
    "    if(\"Result\" in frame):\n",
    "        frame[\"Result\"] = frame[\"Result\"].replace(Result.WIN.value, \"Win\").replace(Result.LOSS.value, \"Loss\")\n",
    "        return frame\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is unused. Was used in testing to make sure CSV merging worked properly.\n",
    "def generate_summary(input_frame:pandas.DataFrame) -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a summation of the raw input data.\n",
    "\n",
    "    Returs -- new dataframe that includes the win-loss ratio as well as the total yards for each\n",
    "    receiver.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    input_frame -- a Pandas DataFrame containing game and player statistics.\n",
    "    \"\"\"\n",
    "    summary_frame = pandas.DataFrame()\n",
    "    for column in input_frame.columns:\n",
    "        if(column.lower() == \"result\"):\n",
    "            win_loss_counts = input_frame[column].value_counts()\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            if(\"Win\" in win_loss_counts):\n",
    "                wins = int(win_loss_counts[\"Win\"])\n",
    "            if(\"Loss\" in win_loss_counts):\n",
    "                losses = int(win_loss_counts[\"Loss\"])\n",
    "            summary_frame[column] = [\"%s-%s\"%(wins,losses)]\n",
    "        elif(\"yards\" in column.lower() or \"td\" in column.lower()):\n",
    "            try:\n",
    "                summary_frame[column] = input_frame[column].sum(numeric_only=True)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    return summary_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the CSV files from S3\n",
    "s3 = MIND_S3(aws_access_key,aws_secret_key)\n",
    "objects = s3.list_all_objects(aws_s3_bucket)\n",
    "files = s3.pull_objects(aws_s3_bucket,\"./temp\",objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and transform data from CSV files.\n",
    "input_frame = None\n",
    "for file_name in files:\n",
    "    parsed_frame = parse_CSV_file(file_name)\n",
    "    if(input_frame is None):\n",
    "        input_frame = parsed_frame\n",
    "    elif(parsed_frame is not None):\n",
    "        input_frame = input_frame.merge(parsed_frame,how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcd907ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = MIND_Postgres(\n",
    "    postgres_host,\n",
    "    postgres_port,\n",
    "    postgres_user,\n",
    "    postgres_password,\n",
    "    postgres_database\n",
    ")\n",
    "existing_columns = pg.list_columns(postgres_table)\n",
    "\n",
    "# Add columns if they don't exist\n",
    "for column in input_frame.columns:\n",
    "    sanitized_name = pg.sanitize_column_name(column)\n",
    "    existing_filtered = list(filter(lambda _: _[0] == sanitized_name,existing_columns))\n",
    "    if(len(existing_filtered) <= 0):\n",
    "        print(\"Adding new column: %s\"%(sanitized_name))\n",
    "        try:\n",
    "            int(input_frame[column].sum())\n",
    "            pg.add_column(postgres_table,sanitized_name,\"NUMERIC\")\n",
    "        except Exception as e:\n",
    "            pg.add_column(postgres_table,sanitized_name,\"VARCHAR(64)\")\n",
    "\n",
    "# Clear table of existing data\n",
    "pg.clear_table(postgres_table)\n",
    "\n",
    "# Push new data\n",
    "pg.push_data_frame(input_frame,postgres_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
